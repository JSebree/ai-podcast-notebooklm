import sys, logging
from utils.web_search_utils   import fetch_top_news, enrich_story
from agents.compiler_agent    import run as compiler_run
from utils.google_docs_utils  import create_daily_doc

logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

def main():
    # 1Ô∏è‚É£ Curate
    logger.info("üîç Fetching top tech stories‚Ä¶")
    stories = fetch_top_news(max_items=5)
    if not stories:
        logger.error("No stories fetched; aborting.")
        sys.exit(1)

    # 2Ô∏è‚É£ Research
    logger.info("üîé Enriching each story‚Ä¶")
    enriched = []
    for s in stories:
        try:
            enriched.append(enrich_story(s))
        except Exception as e:
            logger.error("Enrichment error on %r: %s", s.get("title"), e)
    if not enriched:
        logger.error("No enriched stories; aborting.")
        sys.exit(1)

    # 3Ô∏è‚É£ Compile
    logger.info("‚úçÔ∏è Compiling summaries‚Ä¶")
    compiled = compiler_run(enriched)
    if not isinstance(compiled, list) or not compiled:
        logger.error("Compilation failed or empty; aborting.")
        sys.exit(1)

    # 4Ô∏è‚É£ Create Google Doc
    logger.info("üìÑ Creating Google Doc‚Ä¶")
    try:
        url = create_daily_doc(compiled)
    except Exception:
        logger.exception("Doc creation failed")
        sys.exit(1)

    logger.info("‚úÖ All done! Document is at: %s", url)
    # Print for GitHub logs
    print("\nüçç Daily Digest URL:", url)

if __name__ == "__main__":
    main()
